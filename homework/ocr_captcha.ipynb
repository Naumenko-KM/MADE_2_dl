{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=unused-import\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 802\n",
      "test size: 268\n",
      "unique chars: 19\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir('./dataset')\n",
    "train_images, test_images = train_test_split(images, shuffle=True, train_size=0.75, random_state=RANDOM_STATE)\n",
    "print('train size:', len(train_images))\n",
    "print('test size:', len(test_images))\n",
    "\n",
    "\n",
    "chars = list(map(lambda x: x[:-4], images))\n",
    "chars = ''.join(chars)\n",
    "chars = set(chars)\n",
    "NUM_CHARS = len(chars)\n",
    "print('unique chars:', len(chars))\n",
    "\n",
    "idx2char = {k: v for k, v in enumerate(chars, start=0)}\n",
    "char2idx = {k: v for v, k in idx2char.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, images, img_dir='./dataset/', transform=None):\n",
    "        self.images = images\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        label = self.images[idx][:-4]\n",
    "        label = torch.Tensor([char2idx[char] for char in label])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=0.5, std=0.25)\n",
    "        ])\n",
    "\n",
    "train_dataset = CaptchaDataset(train_images, transform=transform)\n",
    "test_dataset = CaptchaDataset(test_images, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 50, 200]), torch.Size([64, 5]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y =next(iter(train_dataloader))\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 19])\n"
     ]
    }
   ],
   "source": [
    "class OCRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OCRModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2, 3))\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2, 3))\n",
    "        \n",
    "        self.linear1 = nn.Linear(1536, 64)\n",
    "        self.lstm = nn.LSTM(64, 32, bidirectional=True, num_layers=2, dropout=0.2, batch_first=True)\n",
    "        self.linear2 = nn.Linear(64, NUM_CHARS)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  [batch, 1, 50, 200]\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x)))) #  [batch, 64, 25, 100]\n",
    "        x = F.relu(self.pool2(self.bn2(self.conv2(x)))) #  [batch, 128, 12, 50]\n",
    "        x = F.relu(self.pool3(self.bn3(self.conv3(x)))) #  [batch, 256, 6, 16]\n",
    "        x = self.pool4(self.bn4(self.conv4(x))) #  [batch, 512, 3, 5]\n",
    "        x = x.permute(0, 3, 1, 2) #  [batch, 5, 512, 3]\n",
    "        x = x.view(x.shape[0], x.shape[1], -1) #  [batch, 5, 1536]\n",
    "        x = F.relu(self.linear1(x)) #  [batch, 5, 64]\n",
    "        x, _ = self.lstm(x) #  [batch, 5, 64]\n",
    "        x = self.linear2(x) #  [batch, 5, 19]\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = OCRModel()\n",
    "    model.eval()\n",
    "    x, y = next(iter(train_dataloader))\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n",
      "torch.Size([64, 19, 5]) torch.Size([64, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         \u001b[39mprint\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mFinished Training\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m train_model(model, criterion, optimizer, train_dataloader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m preds \u001b[39m=\u001b[39m preds\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(preds\u001b[39m.\u001b[39mshape, labels\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb Cell 10\u001b[0m in \u001b[0;36mOCRModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m#  [batch, 1, 50, 200]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))) \u001b[39m#  [batch, 64, 25, 100]\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x)))) \u001b[39m#  [batch, 128, 12, 50]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(x)))) \u001b[39m#  [batch, 256, 6, 16]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool4(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn4(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv4(x))) \u001b[39m#  [batch, 512, 3, 5]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/ML/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = OCRModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_model(model, criterion, optimizer, trainloader, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs)\n",
    "            preds = preds.permute(0, 2, 1)\n",
    "            loss = criterion(preds, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:\n",
    "                print('Epoch {0}/{1}, iteration {2}, loss: {3:.3f}'.format(epoch + 1, num_epochs, i + 1, \n",
    "                                                                          running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        print()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "\n",
    "train_model(model, criterion, optimizer, train_dataloader, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[0, 2, 1]' is invalid for input of size 6080",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_model(model, criterion, optimizer, train_dataloader, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "\u001b[1;32m/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb Cell 11\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m preds \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m preds\u001b[39m.\u001b[39;49mreshape(\u001b[39m0\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(preds\u001b[39m.\u001b[39mshape, labels\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kostia/Learning/MADE_2_dl/homework/ocr_captcha.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(preds, labels)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[0, 2, 1]' is invalid for input of size 6080"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 512, 3, 12])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "preds = model(x)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 18, 72])\n",
      "torch.Size([1, 72, 64, 18])\n",
      "torch.Size([1, 72, 1152])\n",
      "torch.Size([1, 72, 64])\n"
     ]
    }
   ],
   "source": [
    "class CaptchaModel(nn.Module):\n",
    "    def __init__(self, num_chars):\n",
    "        super(CaptchaModel, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 128, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.conv_2 = nn.Conv2d(128, 64, kernel_size=(3, 6), padding=(1, 1))\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.linear_1 = nn.Linear(1152, 64)\n",
    "        self.drop_1 = nn.Dropout(0.2)\n",
    "        self.lstm = nn.GRU(64, 32, bidirectional=True, num_layers=2, dropout=0.25, batch_first=True)\n",
    "        self.output = nn.Linear(64, num_chars + 1)\n",
    "\n",
    "    def forward(self, images, targets=None):\n",
    "        bs, _, _, _ = images.size()\n",
    "        x = F.relu(self.conv_1(images))\n",
    "        x = self.pool_1(x)\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = self.pool_2(x)\n",
    "        print(x.shape)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        print(x.shape)\n",
    "        x = x.view(bs, x.size(1), -1)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.linear_1(x))\n",
    "        print(x.shape)\n",
    "        x = self.drop_1(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.output(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "\n",
    "        if targets is not None:\n",
    "            log_probs = F.log_softmax(x, 2)\n",
    "            input_lengths = torch.full(\n",
    "                size=(bs,), fill_value=log_probs.size(0), dtype=torch.int32\n",
    "            )\n",
    "            target_lengths = torch.full(\n",
    "                size=(bs,), fill_value=targets.size(1), dtype=torch.int32\n",
    "            )\n",
    "            loss = nn.CTCLoss(blank=0)(\n",
    "                log_probs, targets, input_lengths, target_lengths\n",
    "            )\n",
    "            return x, loss\n",
    "\n",
    "        return x, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cm = CaptchaModel(19)\n",
    "    img = torch.rand((1, 3, 75, 300))\n",
    "    x, _ = cm(img, torch.rand((1, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1dbbfb2e33f52a21c63ec41f686d0c232de0dcaa0d25c0bcda0f19c58d57e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
