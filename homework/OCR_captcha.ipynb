{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 802\n",
      "test size: 268\n",
      "unique chars: 19\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir('./laba-dataset')\n",
    "train_images, test_images = train_test_split(images, shuffle=True, train_size=0.75, random_state=RANDOM_STATE)\n",
    "print('train size:', len(train_images))\n",
    "print('test size:', len(test_images))\n",
    "\n",
    "\n",
    "chars = list(map(lambda x: x[:-4], images))\n",
    "chars = ''.join(chars)\n",
    "chars = set(chars)\n",
    "print('unique chars:', len(chars))\n",
    "\n",
    "idx2char = {k: v for k, v in enumerate(chars, start=0)}\n",
    "char2idx = {k: v for v, k in idx2char.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, images, img_dir='./laba-dataset/', transform=None):\n",
    "        self.images = images\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('L')\n",
    "        label = self.images[idx][:-4]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 802\n",
      "test size: 268\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=0.5, std=0.25)\n",
    "        ])\n",
    "\n",
    "train_dataset = CaptchaDataset(train_images, transform=transform)\n",
    "test_dataset = CaptchaDataset(test_images, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]],\n",
       " \n",
       " \n",
       "         [[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]],\n",
       " \n",
       " \n",
       "         [[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]],\n",
       " \n",
       " \n",
       "         [[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]],\n",
       " \n",
       " \n",
       "         [[[1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           [1.0118, 1.0118, 1.0118,  ..., 1.9373, 1.9373, 1.9373],\n",
       "           ...,\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843],\n",
       "           [1.0588, 1.0588, 1.0588,  ..., 1.9843, 1.9843, 1.9843]]]]),\n",
       " ('87d4c',\n",
       "  'ng756',\n",
       "  '244e2',\n",
       "  '34pcn',\n",
       "  'd7c5x',\n",
       "  'mdyp7',\n",
       "  '8n5p3',\n",
       "  'deep5',\n",
       "  '62nb3',\n",
       "  '7gce6',\n",
       "  '8n4n8',\n",
       "  '5mnpd',\n",
       "  'b4ndb',\n",
       "  'yyn57',\n",
       "  'yeyn4',\n",
       "  'mmy5n',\n",
       "  '5nnff',\n",
       "  'b6f2p',\n",
       "  'bdbb3',\n",
       "  '3xcgg',\n",
       "  'p2ym2',\n",
       "  'pwebm',\n",
       "  'nn4wx',\n",
       "  '8684m',\n",
       "  '7dwx4',\n",
       "  'y2ye8',\n",
       "  'cd6p4',\n",
       "  'n2by7',\n",
       "  '8n5pn',\n",
       "  'm75bf',\n",
       "  '373gb',\n",
       "  'mcg43',\n",
       "  'mpmy5',\n",
       "  '2cegf',\n",
       "  'cnmnn',\n",
       "  '73mnx',\n",
       "  'pgg3n',\n",
       "  '2w4y7',\n",
       "  'yy824',\n",
       "  'w8f36',\n",
       "  '53mn8',\n",
       "  '6p7gx',\n",
       "  'fgb36',\n",
       "  '6e554',\n",
       "  '5n728',\n",
       "  'bbymy',\n",
       "  'cfw6e',\n",
       "  '55y2m',\n",
       "  'pgwnp',\n",
       "  'e6b7y',\n",
       "  'g6n7x',\n",
       "  'wddcp',\n",
       "  'mgdwb',\n",
       "  'n3m6x',\n",
       "  'd75b5',\n",
       "  'pyefb',\n",
       "  'nxf2c',\n",
       "  '2bg48',\n",
       "  'd2n8x',\n",
       "  '7p852',\n",
       "  'c55c6',\n",
       "  '53wb8',\n",
       "  'n8pfe',\n",
       "  '4dgf7'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y =next(iter(train_dataloader))\n",
    "x, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b1dbbfb2e33f52a21c63ec41f686d0c232de0dcaa0d25c0bcda0f19c58d57e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
